{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J7F1UxrO0c-"
      },
      "source": [
        "# Demo arquitecturas avanzadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpf1dFtbQSDq"
      },
      "source": [
        "## Modelo master-slave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2fE_ePuPffC"
      },
      "source": [
        "### Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t9apNo4cPdbd"
      },
      "outputs": [],
      "source": [
        "import socket\n",
        "import threading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJBrav0fPr8j"
      },
      "source": [
        "### Master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "122FSJJuPjJD"
      },
      "outputs": [],
      "source": [
        "def master(task):\n",
        "    # Crear un socket TCP/IP\n",
        "    master_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "\n",
        "    # Conectarse al Slave\n",
        "    master_socket.connect(('localhost', 9999))\n",
        "\n",
        "    try:\n",
        "        # Enviar la tarea al Slave\n",
        "        master_socket.sendall(task.encode())\n",
        "        print(f\"Master - Envió tarea: {task}\")\n",
        "\n",
        "        # Esperar la respuesta del Slave\n",
        "        result = master_socket.recv(1024).decode()\n",
        "        print(f\"Master - Recibió resultado: {result}\")\n",
        "    finally:\n",
        "        # Cerrar la conexión\n",
        "        master_socket.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXGx7FTnPtm-"
      },
      "source": [
        "### Slave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZuvQQBHPu3v"
      },
      "outputs": [],
      "source": [
        "def slave():\n",
        "    # Crear un socket TCP/IP\n",
        "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server_socket.bind(('localhost', 9999))\n",
        "    server_socket.listen(1)\n",
        "    print(\"Slave esperando tareas...\")\n",
        "\n",
        "    while True:\n",
        "        # Esperar a que un cliente se conecte\n",
        "        connection, client_address = server_socket.accept()\n",
        "        try:\n",
        "            print(f\"Slave - Conexión establecida con {client_address}\")\n",
        "\n",
        "            # Recibir la tarea (mensaje) del Master\n",
        "            task = connection.recv(1024).decode()\n",
        "            print(f\"Slave - Recibió tarea: {task}\")\n",
        "\n",
        "            # Procesar la tarea (simulación)\n",
        "            result = f\"Resultado de {task}\"\n",
        "\n",
        "            # Enviar el resultado de vuelta al Master\n",
        "            connection.sendall(result.encode())\n",
        "        finally:\n",
        "            # Cerrar la conexión\n",
        "            connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TRf2RMEP3ku",
        "outputId": "e898c961-b8c3-44ad-cb59-ef8c9cfd898f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slave esperando tareas...\n"
          ]
        }
      ],
      "source": [
        "slave_thread = threading.Thread(target=slave, daemon=True)\n",
        "slave_thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFeBMpefQLVm",
        "outputId": "db63978d-7fed-4e11-cb61-fe8a2f611565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slave - Conexión establecida con ('127.0.0.1', 48384)\n",
            "Slave - Recibió tarea: calcular la suma de 2+2\n",
            "Master - Envió tarea: calcular la suma de 2+2\n",
            "Master - Recibió resultado: Resultado de calcular la suma de 2+2\n"
          ]
        }
      ],
      "source": [
        "# Enviar una tarea desde el Master al Slave\n",
        "master(\"calcular la suma de 2+2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DJAkkyxQMH-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHgqLkJgQUt7"
      },
      "source": [
        "## Entrenamiendo AI/ML en CPUs, GPUs y TPUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnG5m2RaQc90"
      },
      "source": [
        "### Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8s1xlyA_QYoD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7aMzhOpQiH2"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI11mvzHQd4g",
        "outputId": "3ca19d0f-1770-4238-9e21-ba2452aa5766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKDxf1jmQ1DV"
      },
      "source": [
        "### Acceso a TPUs para entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kBaDaIimQyYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b76a5b7-cf4f-4884-d43d-f4650c1e3a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No TPU found\n"
          ]
        }
      ],
      "source": [
        "# Intenta encontrar y configurar una TPU\n",
        "try:\n",
        "    # Resolver la TPU disponible en el entorno, especialmente en Google Colab.\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "\n",
        "    # Conectar al clúster de TPU, lo que permite que TensorFlow coordine las comunicaciones entre los nodos de la TPU.\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "\n",
        "    # Inicializar el sistema TPU para que esté listo para usar. Esto configura la TPU para el entrenamiento.\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "\n",
        "    # Imprime todos los dispositivos lógicos que corresponden a la TPU.\n",
        "    # Esto es útil para verificar si las TPUs se han detectado correctamente.\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "    # Define una estrategia de distribución para usar la TPU, lo que permite el uso de TPUs para la distribución de tareas.\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "# Si no se encuentra ninguna TPU, se captura la excepción ValueError\n",
        "except ValueError:\n",
        "    # Si no se encuentra una TPU, se usa la estrategia por defecto, que puede ser CPU o GPU según lo que esté disponible.\n",
        "    print(\"No TPU found\")\n",
        "    strategy = tf.distribute.get_strategy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8honGmyRwgT"
      },
      "source": [
        "### Definición del modelo (CNN) y Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy']) # Now 'accuracy' is created within the TPUStrategy scope\n",
        "\n",
        "    model.fit(train_images,\n",
        "              train_labels,\n",
        "              epochs=10,\n",
        "              validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO1oVrCszGpa",
        "outputId": "6f3244ab-1209-45cd-e6a1-ee32e5b151cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.3549 - loss: 1.7477 - val_accuracy: 0.5504 - val_loss: 1.2541\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.5766 - loss: 1.1841 - val_accuracy: 0.6119 - val_loss: 1.0929\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6443 - loss: 1.0103 - val_accuracy: 0.6057 - val_loss: 1.1255\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.9128 - val_accuracy: 0.6691 - val_loss: 0.9386\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.8384 - val_accuracy: 0.6744 - val_loss: 0.9267\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.7719 - val_accuracy: 0.7000 - val_loss: 0.8572\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7515 - loss: 0.7126 - val_accuracy: 0.7000 - val_loss: 0.8783\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.6749 - val_accuracy: 0.7051 - val_loss: 0.8511\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7738 - loss: 0.6431 - val_accuracy: 0.6958 - val_loss: 0.9132\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7890 - loss: 0.5949 - val_accuracy: 0.7181 - val_loss: 0.8451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7Wgii_1azYqI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC3OwYRbR8ma"
      },
      "source": [
        "### Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdz_F4yARS0L",
        "outputId": "4209d52c-d95c-49f7-b44a-0f29f314a9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 0s - 2ms/step - accuracy: 0.7181 - loss: 0.8451\n",
            "\n",
            "Test accuracy: 0.7181000113487244\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGkGj3O0R-Y1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}